# ACyLeR: An enhanced iTransformer for Long-Term Time-Series Forecasting Using Adaptive Cycling Learning Rate

## Overview
- ACyLeR is a novel approach for time-series forecasting
- Utilizes an enhanced iTransformer model
- Adaptive cycling learning rate for improved performance

## Components
1. **iTransformer Model**
   - **Description**: A deep learning model for time-series forecasting
   - **Key Features**: 
     - Encoder-decoder architecture
     - Self-attention mechanism
     - Transformer-based architecture

2. **Adaptive Cycling Learning Rate**
   - **Description**: A learning rate adjustment strategy
   - **Purpose**: To optimize model training and improve forecasting accuracy
   - **Implementation**: 
     - Cycle-based learning rate adjustments
     - Periodic changes in learning rate values

3. **Long-Term Time-Series Forecasting**
   - **Description**: Application of ACyLeR model for predicting future values in time-series data
   - **Benefits**:
     - Improved forecasting accuracy
     - Better handling of long-term dependencies

## Results
- **Evaluation Metrics**: Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Mean Absolute Percentage Error (MAPE)
- **Performance**: ACyLeR outperforms baseline models in terms of forecasting accuracy

## Conclusion
- ACyLeR is a promising approach for long-term time-series forecasting
- Adaptive cycling learning rate significantly enhances model performance
- Further research is needed to explore its application in diverse time-series domains